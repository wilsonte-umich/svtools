
# get passed arguments
sample          <- Sys.getenv("sample")
pdfDir          <- Sys.getenv("pdfDir")
cnvFile         <- Sys.getenv("cnvFile")
cnvSizeStep     <- as.numeric(Sys.getenv("cnvSizeStep"))
minCnvSize      <- as.numeric(Sys.getenv("minCnvSize"))
maxCnvSize      <- as.numeric(Sys.getenv("maxCnvSize"))

# set boundaries on alternative (CNV) models
write("  setting CNV size bounds", file=stderr())
minTLen  <- -maxCnvSize;
maxTLen  <- 2 * maxCnvSize;
cnvTypes <- c('del', 'ins', 'dup')
cnvSizes <- list(
    'del' =   seq( minCnvSize,  maxCnvSize, cnvSizeStep),    
    'dup' =   seq(-maxCnvSize, -minCnvSize, cnvSizeStep),
    'ins' =   seq(-maxCnvSize, -minCnvSize, cnvSizeStep),
    'all' = c(0,
              seq(-maxCnvSize, -minCnvSize, cnvSizeStep),
              seq( minCnvSize,  maxCnvSize, cnvSizeStep))
)
cnvFracs <- seq(0, 1, 0.05)

# get the expected TLEN frequency distributions
#   generated by svtools pdf for the same libraries/sample
write("  loading library TLEN distributions", file=stderr())
distFile      <- paste(pdfDir, "/svtools.pdf.", sample, ".all.gz", sep="")
dist          <- read.table(distFile, header=FALSE, sep="\t", stringsAsFactors=FALSE)
colnames(dist)<- c('tLen', 'freq')
dist          <- dist[dist$tLen>=minTLen&dist$tLen<=maxTLen,]
dist_freq     <- stepfun(dist$tLen, c(0, dist$freq))

# set boundaries on interrogated TLENs
write("  setting TLEN bounds", file=stderr())
tLenBin <- dist[2,'tLen'] - dist[1,'tLen']
tLens   <- seq(minTLen, maxTLen, tLenBin)

# calculate weighted frequency for crossing fragments of TLEN based on CNV size
#   dist has size frequency by fragment _count_
#   need to weight by abs(TLEN) to get the probablity that 
#   a given position will cross a mapped span of a given length
weightFreqs <- function(freq, tLen){
    wF <- freq * abs(tLen)
    wF / sum(wF)
}

# establish pure models (fracCnv==1) for all allowed cnv sizes
#   these models only consider anomalous pairs
#   not the proper pairs that map within a dup span
#   allow negative fragSize at cnvSize==0 to account for occasional misalignment
#   set CNV freq to zero at negative fragment sizes (allowing for rounding errors)
write("  constructing pure anomalous pair models for all CNV sizes", file=stderr())
pdfs <- list()
for (cnvSize in cnvSizes[['all']]){
    fragSizes   <- tLens - cnvSize
    minFragSize <- if(cnvSize==0) { minTLen } else { -tLenBin } 
    freqs       <- ifelse(fragSizes < minFragSize, 0, dist_freq(fragSizes))
    wF          <- weightFreqs(freqs, tLens)
    pdfs[[as.character(cnvSize)]] <- stepfun(tLens, c(0, wF))
}    
pdf_ref <- pdfs[['0']]

# establish mixed models of ref + alt for combination of cnvType, cnvSize and cnvFrac
#   values are the CDF values at all stepped tLens
#   allow negative TLEN for dup, but not for ins (not applicable to del)
write("  constructing mixed pair models for all CNV models", file=stderr())
mdl_cdfs <- list()
mdl_prms <- list()
mdlIs    <- list()
get_mdl <- function(cnvType, cnvSize, cnvFrac){
    pdf_alt <- ifelse(             
        cnvType == 'ins' & tLens < 0,              
        0,          
        pdf_ref(tLens) * (1 - cnvFrac) + pdf_ref(tLens - cnvSize) * cnvFrac                  
    )
    cumsum(pdf_alt / sum(pdf_alt))     
}
for(cnvType in cnvTypes){
    mdl_cdfs[[cnvType]] <- list()
    mdl_prms[[cnvType]] <- list()
    mdlI_wrk <- 1
    for(cnvSize in cnvSizes[[cnvType]]){
        for(cnvFrac in cnvFracs){
            mdl_cdfs[[cnvType]][[mdlI_wrk]] <- get_mdl(cnvType, cnvSize, cnvFrac)
            mdl_prms[[cnvType]][[mdlI_wrk]] <- list(cnvSize, cnvFrac)
            mdlI_wrk <- mdlI_wrk + 1
        }  
    }
    mdlIs[[cnvType]] <- 1:(mdlI_wrk-1)
}

# perform AUC minimization by cnvType
cdf_act_val <- numeric()
mdl_cdf_wrk <- list()
fill_diff <- Vectorize(function(mdlI){
    sum(abs(cdf_act_val - mdl_cdf_wrk[[mdlI]]))
})

# analyze each cnv run
#   report results as deltaCDF_alt, cnvType, cnvSize, cnvFrac
analyze_cnv <- function(cnv){
    tL           <- as.numeric(strsplit(cnv[1], ",")[[1]])
    cdf_act_val <<- ecdf(tL)(tLens)         
    nNeg         <- length(tL[tL<0])
    cnvType <- if(as.numeric(cnv[2]) < 0){
        'del'
    } else if(nNeg > 0){
        'dup'
    } else {
        'ins'
    }
    mdl_cdf_wrk <<- mdl_cdfs[[cnvType]]
    diff         <- fill_diff(mdlIs[[cnvType]])
    mdlI         <- which(diff == min(diff))[1]    
    mdl          <- mdl_prms[[cnvType]][[mdlI]]
    deltaCDF_alt <- round(diff[mdlI], 1)  
    paste(c(deltaCDF_alt, cnvType, -mdl[[1]], round(mdl[[2]],2)), collapse="\t")
}

# get the list of CNVs to analyze
write("  loading cnv data", file=stderr())
cnvs <- read.table(cnvFile, header=FALSE, sep="\t", stringsAsFactors=FALSE)
colnames(cnvs) <- c('chrom', 'start', 'end', 'sample', 'nBins', 'strand',
                    'nFrags', 'fracLowQual', 'tLens', 'isGap', 'n_log_p', 'deltaCDF_abs', 'deltaCDF_sgn')
cnvs$output <- ""

# do the analysis and return the results
write("  calculating cnv values", file=stderr())
for (chrom in unique(cnvs$chrom)) {
    write(paste("    ", chrom, sep=""), file=stderr())
    is <- which(cnvs$chrom==chrom)
    cnvs[is,'output'] <- apply(cnvs[is,c('tLens','deltaCDF_sgn')], 1, analyze_cnv)
}
write.table(
    cnvs,
    file      = "",
    quote     = FALSE,
    sep       = "\t",
    row.names = FALSE,
    col.names = FALSE
) 

